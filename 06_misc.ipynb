{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to compute UTS\n",
    "Utility function to compute the signatures for any input array. You might have to apply additional normalization if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.metrics import METRICS_CONFIG\n",
    "\n",
    "def compute_metrics(vectors):\n",
    "    results_data = []\n",
    "    computed_metrics = []\n",
    "    for metric in METRICS_CONFIG[\"metrics\"]:\n",
    "        compute_func = METRICS_CONFIG[\"metrics\"][metric][\"compute_func\"]\n",
    "        max_sample_size = METRICS_CONFIG[\"metrics\"][metric][\"max_sample_size\"]\n",
    "        is_local = METRICS_CONFIG[\"metrics\"][metric].get(\"is_local\", False)\n",
    "        kwargs = METRICS_CONFIG[\"metrics\"][metric][\"kwargs\"]\n",
    "        requires_distance = METRICS_CONFIG[\"metrics\"][metric].get(\"requires_distance\", False)\n",
    "        distance_metrics = METRICS_CONFIG.get(\"distance_metrics\", [])\n",
    "\n",
    "        if is_local:\n",
    "            continue\n",
    "\n",
    "        for distance_metric in distance_metrics:\n",
    "            if requires_distance:\n",
    "                kwargs[\"distance_metric\"] = distance_metric\n",
    "                computed_metrics.append(f\"{metric}_{distance_metric}\")\n",
    "            else:\n",
    "                computed_metrics.append(metric)\n",
    "            \n",
    "            if vectors.shape[0] > max_sample_size:\n",
    "                # Sample from vectors\n",
    "                sample_indices = np.random.choice(vectors.shape[0], size=max_sample_size, replace=False)\n",
    "                vectors_capped = vectors[sample_indices]\n",
    "            else:\n",
    "                vectors_capped = vectors.copy()\n",
    "\n",
    "            result = compute_func(vectors_capped)\n",
    "            results_data.append(result)\n",
    "\n",
    "            if not requires_distance:\n",
    "                # Just one iteration needed\n",
    "                break\n",
    "            \n",
    "    results = {k: v for k, v in zip(computed_metrics, results_data)}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to check processing status\n",
    "\n",
    "Here you can check how many embeddings have been computed and if the MTEB results are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for files at:  results/google/gemini-embedding-001/google__gemini-embedding-001\n",
      "ERROR: No revision found.\n",
      "Looking for files at:  results/google/gemini-embedding-001/google__gemini-embedding-001\n",
      "ERROR: No revision found.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>mteb_results</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>shape</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClimateFEVER</td>\n",
       "      <td>google/gemini-embedding-001</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>(5418127, 3072)</td>\n",
       "      <td>66577944576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSMARCO</td>\n",
       "      <td>google/gemini-embedding-001</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>(8848640, 3072)</td>\n",
       "      <td>108732088320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           task                        model  mteb_results  embeddings   \n",
       "0  ClimateFEVER  google/gemini-embedding-001         False        True  \\\n",
       "1       MSMARCO  google/gemini-embedding-001         False        True   \n",
       "\n",
       "             shape          size  \n",
       "0  (5418127, 3072)   66577944576  \n",
       "1  (8848640, 3072)  108732088320  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from mteb.models.cache_wrapper import TextVectorMap\n",
    "from config.eval import RETRIEVAL_TASKS\n",
    "load_dotenv()\n",
    "\n",
    "# Put here the models you want to check\n",
    "MODELS = [\"google/gemini-embedding-001\"]\n",
    "\n",
    "results = []\n",
    "for task in RETRIEVAL_TASKS:\n",
    "    for model in MODELS:\n",
    "        embeddings = False\n",
    "        shape = 0\n",
    "        size = 0\n",
    "        try:\n",
    "            # Load embeddings memmap\n",
    "            cache_path = os.environ.get(\"CACHE_PATH\") + f\"cache_{model.replace('/', '_')}\" + f\"/{task}\"\n",
    "            data = TextVectorMap(cache_path)\n",
    "            data.load(name=task)\n",
    "\n",
    "            last_non_zero_row = data.vectors.shape[0] - 1\n",
    "            while last_non_zero_row >= 0 and np.all(data.vectors[last_non_zero_row] == 0):\n",
    "                last_non_zero_row -= 1\n",
    "\n",
    "            truncated_data = data.vectors[:last_non_zero_row]\n",
    "\n",
    "            # Remove padding vectors\n",
    "            vectors = np.asarray(truncated_data)\n",
    "            shape = vectors.shape\n",
    "            size = vectors.nbytes\n",
    "            embeddings = True\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Look for mteb results\n",
    "        mteb = False\n",
    "        try:\n",
    "            org_model = model.split(\"/\")\n",
    "            org = org_model[0]\n",
    "\n",
    "            if len(model) > 2:\n",
    "                model_dir = \"_\".join(org_model[1:])\n",
    "            else:\n",
    "                model_dir = org_model[1]\n",
    "            if org == \"dunzhang\":\n",
    "                model_path = f\"NovaSearch__{model_dir}\"\n",
    "            else:\n",
    "                model_path = f\"{org}__{model_dir}\"\n",
    "            path = f\"results/{org}/{model_dir}/{model_path}\"\n",
    "            print(\"Looking for files at: \", path)\n",
    "            if list(os.walk(path)) == []:\n",
    "                print(\"ERROR: No revision found.\")\n",
    "            print(\"Revisions: \", list(os.walk(path))[0][1])\n",
    "            assert len(list(os.walk(path))[0][1]) == 1, \"There should be exactly one revision folder.\"\n",
    "            revision = list(os.walk(path))[0][1][0]\n",
    "            result_path = f\"{path}/{revision}/\"\n",
    "            path = result_path + f\"/{task}.json\"\n",
    "            with open(path, 'r') as file:\n",
    "                mteb_results = json.load(file)\n",
    "            mteb = True\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        results.append({\n",
    "            \"task\": task,\n",
    "            \"model\": model,\n",
    "            \"mteb_results\": mteb,\n",
    "            \"embeddings\": embeddings,\n",
    "            \"shape\": shape,\n",
    "            \"size\": size,\n",
    "        })\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
